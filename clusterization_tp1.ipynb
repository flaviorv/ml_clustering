{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX+pbPLP4ocN6yT39SzHm9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flaviorv/ml_clustering/blob/main/clusterization_tp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question 2 - Clusterization with K-Means"
      ],
      "metadata": {
        "id": "KVB6rvsxYVMc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "iELliS0Ph-7Q"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# loading the dataset and setting column names\n",
        "path = kagglehub.dataset_download(\"lakritidis/product-classification-and-categorization\")\n",
        "dataset = pd.read_csv(path + '/shopmania.csv', header=None)\n",
        "dataset.columns = ['product_id', 'product', 'category_id', 'category']\n",
        "\n",
        "# tfidf vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "vec_product = vectorizer.fit_transform(dataset['product'])\n",
        "\n",
        "# encoding the nominal categorical feature\n",
        "enc_category = pd.get_dummies(dataset['category'], drop_first=True, dtype=int).to_numpy()\n",
        "\n",
        "# concatenating the two preprocessed features\n",
        "x = hstack([enc_category, vec_product])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# clusterization\n",
        "k = 10\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "dataset['cluster'] = kmeans.fit_predict(x)"
      ],
      "metadata": {
        "id": "ZvyTie_VqWrl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the n terms with the highest weight in each cluster\n",
        "terms = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "def top_terms_per_cluster(kmeans, category_cols_len, n_terms=10):\n",
        "    for i, center in enumerate(kmeans.cluster_centers_[:, category_cols_len:]):\n",
        "        top_indices = center.argsort()[::-1][:n_terms]\n",
        "        print(f\"\\nCluster {i}:\")\n",
        "        print(\", \".join(terms[top_indices]))\n",
        "\n",
        "print(top_terms_per_cluster(kmeans, enc_category.shape[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL2j1iqdFBxv",
        "outputId": "2f32313a-4554-4f13-d254-0a43dc4c2e41"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster 0:\n",
            "iphone, plus, case, for, 6s, samsung, galaxy, phone, hybrid, protective\n",
            "\n",
            "Cluster 1:\n",
            "accessories, beanie, 00, size, hat, women, 039, unbranded, cap, winter\n",
            "\n",
            "Cluster 2:\n",
            "letter, tab, box, pack, 11, white, sheets, binder, legal, file\n",
            "\n",
            "Cluster 3:\n",
            "size, girls, junior, bottoms, tops, dresses, mo, dress, skirts, blue\n",
            "\n",
            "Cluster 4:\n",
            "accessories, 039, women, size, unbranded, 00, oz, black, belt, scarf\n",
            "\n",
            "Cluster 5:\n",
            "men, sleeve, 039, shirt, tops, size, boys, long, short, junior\n",
            "\n",
            "Cluster 6:\n",
            "na, bags, women, 039, size, bag, shoulder, leather, handbags, crossbody\n",
            "\n",
            "Cluster 7:\n",
            "vibrator, anal, silicone, vibrating, black, cock, fantasy, 039, vibe, plug\n",
            "\n",
            "Cluster 8:\n",
            "chair, table, cb2, by, mattress, sofa, with, furniture, black, grey\n",
            "\n",
            "Cluster 9:\n",
            "qty, part, no, per, box, jobst, model, knee, toe, 30\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question 5 - Applying PCA to get dimensionality reduction"
      ],
      "metadata": {
        "id": "dzttJpgJEh0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# transforming category dummies in 2 components\n",
        "components = 2\n",
        "pca = PCA(n_components=components)\n",
        "pca_category = pca.fit_transform(enc_category)\n",
        "\n",
        "x_pca = hstack([pca_category, vec_product])\n",
        "\n",
        "# creating clusters with pca components\n",
        "k = 10\n",
        "kmeans_pca = KMeans(n_clusters=k, random_state=42)\n",
        "dataset['pca_cluster'] = kmeans_pca.fit_predict(x_pca)\n",
        "\n",
        "print(top_terms_per_cluster(kmeans_pca, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMDtrEBXFNKN",
        "outputId": "c81ccd7c-d8d4-4a36-d265-2162f4e3fa82"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster 0:\n",
            "iphone6, plusbar, casebound, 6sct, for0910, samudra, 00, galaxys, protecto, hybridlx\n",
            "\n",
            "Cluster 1:\n",
            "oz06, ml2010, de0240, eau0047, toilettte, of290, casebound, organics, sprayed, fl1060004\n",
            "\n",
            "Cluster 2:\n",
            "accessorires, belt0111, womens, size3, 03906, unbreakable, 00, 000, beaniebk, black360\n",
            "\n",
            "Cluster 3:\n",
            "underwire, womens, size3, 03906, briefcase, qu, part8, no1, black360, topseller\n",
            "\n",
            "Cluster 4:\n",
            "00, jewelrybadger, 000, unbreakable, clothmf, 03906, womens, setlakwe, necklaces, size3\n",
            "\n",
            "Cluster 5:\n",
            "mena, 03906, dogcrate, foodie, shortbread, pet618, bag0111, slim2, teeter, cat5\n",
            "\n",
            "Cluster 6:\n",
            "00, na00971pp, baguette, womens, 03906, size3, bag0111, shoulderdolly, leathercraft, handblown\n",
            "\n",
            "Cluster 7:\n",
            "accessorires, scarfand, 000, unbreakable, womens, size3, 03906, duckie, oz06, grayboe\n",
            "\n",
            "Cluster 8:\n",
            "black360, inch101, snowboardjacke, packable, 03906, with10, model1006a, whiteblack, jacketed, red16\n",
            "\n",
            "Cluster 9:\n",
            "size3, 00, topseller, girly, boysenberry, juniors, sleeved, mo260, botton, shirts\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Question 4 - K-means to vector quantization"
      ],
      "metadata": {
        "id": "vIFk0197dVu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# dataset params\n",
        "n_samples = 100\n",
        "n_features = 2\n",
        "n_clusters = 5\n",
        "\n",
        "# creating the dataset\n",
        "x, y_true = make_blobs(n_samples=n_samples, n_features=n_features, centers=n_clusters, random_state=42)\n",
        "\n",
        "# grouping into clusters\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "kmeans.fit(x)\n",
        "\n",
        "# getting the centroids\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# new samples\n",
        "new_points = np.array([[0, 0], [5, 5], [10, 10], [0 ,1], [3, 20]])\n",
        "\n",
        "# comparing with centr√≥ids to grouping the new points too\n",
        "quantized_labels = kmeans.predict(new_points)\n",
        "\n",
        "print(\"New points:\\n\", new_points)\n",
        "print(\"Quantizated labels:\", quantized_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUrWHwAxdqqX",
        "outputId": "6926ef34-a004-45ad-c9f3-c81b85fc5550"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New points:\n",
            " [[ 0  0]\n",
            " [ 5  5]\n",
            " [10 10]\n",
            " [ 0  1]\n",
            " [ 3 20]]\n",
            "Quantizated labels: [4 2 2 4 0]\n"
          ]
        }
      ]
    }
  ]
}